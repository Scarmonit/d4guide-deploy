name: Update D4 API Data

on:
  schedule:
    # Run Monday and Thursday at 9:00 AM UTC to catch meta changes
    - cron: "0 9 * * 1,4"
  workflow_dispatch:
    inputs:
      scripts:
        description: 'Which scripts to run (maxroll-builds, all, tierlist, d4data, maxroll, builds)'
        required: false
        default: 'maxroll-builds'

jobs:
  update-data:
    runs-on: ubuntu-latest
    timeout-minutes: 30

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '22'

      - name: Run data ingestion
        env:
          INGEST_KEY: ${{ secrets.INGEST_KEY }}
          INGEST_URL: "https://scarmonit.com"
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          SCRIPT="${{ github.event.inputs.scripts || 'maxroll-builds' }}"

          if [ "$SCRIPT" = "all" ]; then
            node scripts/ingest.js
          elif [ "$SCRIPT" = "maxroll-builds" ]; then
            node scripts/ingest-maxroll-builds.js
          elif [ "$SCRIPT" = "tierlist" ]; then
            node scripts/ingest-tierlist.js
          elif [ "$SCRIPT" = "d4data" ]; then
            node scripts/ingest-d4data.js
          elif [ "$SCRIPT" = "maxroll" ]; then
            node scripts/ingest-maxroll.js
          elif [ "$SCRIPT" = "builds" ]; then
            node scripts/ingest-builds.js
          else
            echo "Unknown script: $SCRIPT"
            exit 1
          fi

      - name: Verify data
        run: |
          echo "Ingestion completed. Data verification:"
          echo "- Tier list and builds data sent to /api/ingest endpoint"
          echo "- Data written to D1 via Cloudflare Pages Function"
          echo "- View live data at https://scarmonit.com/api/builds"
